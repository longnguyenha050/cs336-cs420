{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10319043,"sourceType":"datasetVersion","datasetId":6388699},{"sourceId":10334520,"sourceType":"datasetVersion","datasetId":6392981},{"sourceId":213326,"sourceType":"modelInstanceVersion","modelInstanceId":181835,"modelId":204070}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install comet-ml==3.21.0\n!pip install git+https://github.com/openai/CLIP.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T13:15:34.622371Z","iopub.execute_input":"2024-12-30T13:15:34.622734Z","iopub.status.idle":"2024-12-30T13:15:45.273582Z","shell.execute_reply.started":"2024-12-30T13:15:34.622704Z","shell.execute_reply":"2024-12-30T13:15:45.272117Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: comet-ml==3.21.0 in /usr/local/lib/python3.10/dist-packages (3.21.0)\nRequirement already satisfied: websocket-client>=0.55.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml==3.21.0) (1.8.0)\nRequirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.10/dist-packages (from comet-ml==3.21.0) (2.32.3)\nRequirement already satisfied: requests-toolbelt>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml==3.21.0) (1.0.0)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from comet-ml==3.21.0) (1.16.0)\nRequirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from comet-ml==3.21.0) (3.1.1)\nRequirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml==3.21.0) (7.352.0)\nRequirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml==3.21.0) (4.23.0)\nRequirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from comet-ml==3.21.0) (1.16.0)\nRequirement already satisfied: semantic-version>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml==3.21.0) (2.10.0)\nRequirement already satisfied: everett>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from everett[ini]>=1.0.1; python_version > \"3.5\"->comet-ml==3.21.0) (3.4.0)\nRequirement already satisfied: dulwich>=0.20.6 in /usr/local/lib/python3.10/dist-packages (from comet-ml==3.21.0) (0.22.7)\nRequirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from dulwich>=0.20.6->comet-ml==3.21.0) (2.2.3)\nRequirement already satisfied: configobj in /usr/local/lib/python3.10/dist-packages (from everett[ini]>=1.0.1; python_version > \"3.5\"->comet-ml==3.21.0) (5.0.9)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml==3.21.0) (24.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml==3.21.0) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml==3.21.0) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml==3.21.0) (0.20.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet-ml==3.21.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet-ml==3.21.0) (3.10)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet-ml==3.21.0) (2024.8.30)\nCollecting git+https://github.com/openai/CLIP.git\n  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-dakxgfqh\n  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-dakxgfqh\n  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (6.3.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (24.1)\nRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2024.9.11)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.66.5)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.4.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.19.1+cu121)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.13)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2024.6.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (10.4.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip==1.0) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->clip==1.0) (1.3.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 -f 'https://download.pytorch.org/whl/torch_stable.html'\n!pip install pandas==1.4.2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T13:15:45.275438Z","iopub.execute_input":"2024-12-30T13:15:45.275894Z","iopub.status.idle":"2024-12-30T13:18:16.643581Z","shell.execute_reply.started":"2024-12-30T13:15:45.275849Z","shell.execute_reply":"2024-12-30T13:18:16.641558Z"}},"outputs":[{"name":"stdout","text":"Looking in links: https://download.pytorch.org/whl/torch_stable.html\nCollecting torch==1.11.0+cu113\n  Downloading https://download.pytorch.org/whl/cu113/torch-1.11.0%2Bcu113-cp310-cp310-linux_x86_64.whl (1637.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 GB\u001b[0m \u001b[31m616.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torchvision==0.12.0+cu113\n  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.12.0%2Bcu113-cp310-cp310-linux_x86_64.whl (22.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.11.0+cu113) (4.12.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0+cu113) (1.26.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0+cu113) (2.32.3)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0+cu113) (10.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0+cu113) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0+cu113) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0+cu113) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0+cu113) (2024.8.30)\nInstalling collected packages: torch, torchvision\n  Attempting uninstall: torch\n    Found existing installation: torch 2.4.1+cu121\n    Uninstalling torch-2.4.1+cu121:\n      Successfully uninstalled torch-2.4.1+cu121\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.19.1+cu121\n    Uninstalling torchvision-0.19.1+cu121:\n      Successfully uninstalled torchvision-0.19.1+cu121\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npytorch-lightning 2.4.0 requires torch>=2.1.0, but you have torch 1.11.0+cu113 which is incompatible.\nstable-baselines3 2.1.0 requires torch>=1.13, but you have torch 1.11.0+cu113 which is incompatible.\ntorchaudio 2.4.1+cu121 requires torch==2.4.1, but you have torch 1.11.0+cu113 which is incompatible.\ntorchmetrics 1.6.0 requires torch>=2.0.0, but you have torch 1.11.0+cu113 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed torch-1.11.0+cu113 torchvision-0.12.0+cu113\nCollecting pandas==1.4.2\n  Downloading pandas-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.4.2) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.4.2) (2024.2)\nRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas==1.4.2) (1.26.4)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas==1.4.2) (1.16.0)\nDownloading pandas-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: pandas\n  Attempting uninstall: pandas\n    Found existing installation: pandas 2.1.4\n    Uninstalling pandas-2.1.4:\n      Successfully uninstalled pandas-2.1.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\narviz 0.19.0 requires pandas>=1.5.0, but you have pandas 1.4.2 which is incompatible.\nbigframes 1.17.0 requires pandas>=1.5.3, but you have pandas 1.4.2 which is incompatible.\ncudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.4.2 which is incompatible.\ncudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 18.1.0 which is incompatible.\ndask-expr 1.1.21 requires pandas>=2, but you have pandas 1.4.2 which is incompatible.\nfeaturetools 1.31.0 requires pandas>=2.0.0, but you have pandas 1.4.2 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.1.4, but you have pandas 1.4.2 which is incompatible.\nibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 18.1.0 which is incompatible.\nmizani 0.11.4 requires pandas>=2.1.0, but you have pandas 1.4.2 which is incompatible.\npandas-gbq 0.23.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nplotnine 0.13.6 requires pandas<3.0.0,>=2.1.0, but you have pandas 1.4.2 which is incompatible.\npyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.4.2 which is incompatible.\nstable-baselines3 2.1.0 requires torch>=1.13, but you have torch 1.11.0+cu113 which is incompatible.\nvisions 0.7.6 requires pandas>=2.0.0, but you have pandas 1.4.2 which is incompatible.\nwoodwork 0.31.0 requires pandas>=2.0.0, but you have pandas 1.4.2 which is incompatible.\nxarray 2024.9.0 requires pandas>=2.1, but you have pandas 1.4.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pandas-1.4.2\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install urllib3==1.26.15\n!pip install -U comet-ml","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T13:19:56.172646Z","iopub.execute_input":"2024-12-30T13:19:56.173043Z","iopub.status.idle":"2024-12-30T13:20:05.175541Z","shell.execute_reply.started":"2024-12-30T13:19:56.173014Z","shell.execute_reply":"2024-12-30T13:20:05.174031Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: urllib3==1.26.15 in /usr/local/lib/python3.10/dist-packages (1.26.15)\nRequirement already satisfied: comet-ml in /usr/local/lib/python3.10/dist-packages (3.47.6)\nRequirement already satisfied: everett<3.2.0,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from everett[ini]<3.2.0,>=1.0.1->comet-ml) (3.1.0)\nRequirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (4.23.0)\nRequirement already satisfied: psutil>=5.6.3 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (5.9.5)\nRequirement already satisfied: python-box<7.0.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (6.1.0)\nRequirement already satisfied: requests-toolbelt>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (1.0.0)\nRequirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (2.32.3)\nRequirement already satisfied: semantic-version>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (2.10.0)\nRequirement already satisfied: sentry-sdk>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (2.19.2)\nRequirement already satisfied: simplejson in /usr/local/lib/python3.10/dist-packages (from comet-ml) (3.19.3)\nRequirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (1.26.15)\nRequirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (1.16.0)\nRequirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (3.1.1)\nRequirement already satisfied: dulwich!=0.20.33,>=0.20.6 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (0.22.7)\nRequirement already satisfied: rich>=13.3.2 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (13.8.1)\nRequirement already satisfied: configobj in /usr/local/lib/python3.10/dist-packages (from everett[ini]<3.2.0,>=1.0.1->comet-ml) (5.0.9)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (24.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.20.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet-ml) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet-ml) (3.10)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet-ml) (2024.8.30)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet-ml) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet-ml) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet-ml) (0.1.2)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!git clone https://github.com/longnguyenha050/cs336-cs420.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T13:28:31.318101Z","iopub.execute_input":"2024-12-30T13:28:31.318654Z","iopub.status.idle":"2024-12-30T13:28:31.953384Z","shell.execute_reply.started":"2024-12-30T13:28:31.318611Z","shell.execute_reply":"2024-12-30T13:28:31.951939Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'cs336-cs420'...\nremote: Enumerating objects: 70, done.\u001b[K\nremote: Counting objects: 100% (70/70), done.\u001b[K\nremote: Compressing objects: 100% (66/66), done.\u001b[K\nremote: Total 70 (delta 31), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (70/70), 69.88 KiB | 5.38 MiB/s, done.\nResolving deltas: 100% (31/31), done.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import shutil\nimport os\n\n# Define source and destination directories\nsource_dir = '/kaggle/input/fashioniq2'\ndestination_dir = '/kaggle/working/cs336-cs420'\n\n# Define the specific source directories for each folder\ndirectories_to_copy = {\n    'captions': 'captions-20220326T130604Z-001',\n    'image_splits': 'image_splits-20220326T130551Z-001',\n    'images': 'images'\n}\n\n# Loop through each directory and copy it\nfor folder_name, src_subdir in directories_to_copy.items():\n    src_path = os.path.join(source_dir, src_subdir)\n    dest_path = os.path.join(destination_dir, folder_name)\n    \n    # Ensure the destination directory exists\n    os.makedirs(dest_path, exist_ok=True)\n    \n    # Copy the directory content recursively\n    shutil.copytree(src_path, dest_path, dirs_exist_ok=True)\n\nprint(\"Directories copied successfully.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T13:30:49.436978Z","iopub.execute_input":"2024-12-30T13:30:49.437487Z","iopub.status.idle":"2024-12-30T13:43:53.331884Z","shell.execute_reply.started":"2024-12-30T13:30:49.437445Z","shell.execute_reply":"2024-12-30T13:43:53.330666Z"}},"outputs":[{"name":"stdout","text":"Directories copied successfully.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import os\nimport shutil\n\n# Define source and destination directories\nsource_dir = '/kaggle/working/cs336-cs420'\ndestination_dir = os.path.join(source_dir, 'fashionIQ_dataset')\n\n# Create FashionIQ_dataset directory if it does not exist\nos.makedirs(destination_dir, exist_ok=True)\n\n# Define the directories to move\ndirectories_to_move = {\n    'captions/captions': 'captions',\n    'image_splits/image_splits': 'image_splits',\n    'images/images': 'images'\n}\n\n# Loop through each directory and check if it exists before moving\nfor src_subdir, dest_subdir in directories_to_move.items():\n    src_path = os.path.join(source_dir, src_subdir)\n    dest_path = os.path.join(destination_dir, dest_subdir)\n    \n    # Check if the source directory exists\n    if os.path.exists(src_path):\n        # Move the directory to the new location\n        shutil.move(src_path, dest_path)\n        print(f\"Moved {src_path} to {dest_path}\")\n    else:\n        print(f\"Source directory {src_path} does not exist.\")\n\nprint(\"Directories moved successfully.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T13:59:00.237828Z","iopub.execute_input":"2024-12-30T13:59:00.238400Z","iopub.status.idle":"2024-12-30T13:59:00.249966Z","shell.execute_reply.started":"2024-12-30T13:59:00.238364Z","shell.execute_reply":"2024-12-30T13:59:00.247883Z"}},"outputs":[{"name":"stdout","text":"Source directory /kaggle/working/CLIP4Cir/captions/captions does not exist.\nSource directory /kaggle/working/CLIP4Cir/image_splits/image_splits does not exist.\nSource directory /kaggle/working/CLIP4Cir/images/images does not exist.\nDirectories moved successfully.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from PIL import Image\nimport os\n\n# Define the directory containing the images\nimages_dir = '/kaggle/working/cs336-cs420/fashionIQ_dataset/images'\n\n# Loop through all files in the directory\nfor filename in os.listdir(images_dir):\n    if filename.endswith('.png'):  # Check if the file is a PNG image\n        png_path = os.path.join(images_dir, filename)\n        \n        # Open the PNG image\n        with Image.open(png_path) as img:\n            # Convert the image to RGB (required for saving as JPG)\n            rgb_img = img.convert('RGB')\n            \n            # Define the new file path with JPG extension\n            jpg_path = os.path.join(images_dir, filename.replace('.png', '.jpg'))\n            \n            # Save the image as JPG\n            rgb_img.save(jpg_path, 'JPEG')\n\n            # Optionally, delete the original PNG file\n            os.remove(png_path)\n\nprint(\"PNG files have been successfully converted to JPG.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T13:59:05.359250Z","iopub.execute_input":"2024-12-30T13:59:05.359688Z","iopub.status.idle":"2024-12-30T13:59:05.376051Z","shell.execute_reply.started":"2024-12-30T13:59:05.359653Z","shell.execute_reply":"2024-12-30T13:59:05.374251Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-bacb2692f44d>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Loop through all files in the directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Check if the file is a PNG image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mpng_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/CLIP4Cir/fashionIQ_dataset/images'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/working/CLIP4Cir/fashionIQ_dataset/images'","output_type":"error"}],"execution_count":16},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T16:45:09.584295Z","iopub.execute_input":"2024-12-28T16:45:09.584729Z","iopub.status.idle":"2024-12-28T16:45:09.588434Z","shell.execute_reply.started":"2024-12-28T16:45:09.584699Z","shell.execute_reply":"2024-12-28T16:45:09.587425Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"python src/validate.py \n   --dataset FashionIQ \\\n   --combining-function combiner \\\n   --combiner-path /kaggle/input/clipfinetunepy/fiq_clip_RN50x4_fullft.pt \\\n   --projection-dim 2560 \\\n   --hidden-dim 5120 \\\n   --clip-model-name RN50x4 \\\n   --clip-model-path /kaggle/input/clipfinetunepy/fiq_comb_RN50x4_fullft.pt \\\n   --target-ratio 1.25 \\\n   --transform targetpad","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T16:45:38.542014Z","iopub.execute_input":"2024-12-28T16:45:38.542334Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Comet logging ENABLED\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com \u001b[38;5;39mhttps://www.comet.com/longnguyenha050/fashioniq-clip-fine-tuning/880b8a27e29f408aac76783832484703\u001b[0m\n\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\nBoth CLIP encoders will be fine-tuned\n/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n  warnings.warn(\nTarget pad with target_ratio = 1.25 preprocess pipeline is used\nFashionIQ val - ['dress'] dataset in relative mode initialized\nFashionIQ val - ['dress'] dataset in classic mode initialized\nFashionIQ val - ['toptee'] dataset in relative mode initialized\nFashionIQ val - ['toptee'] dataset in classic mode initialized\nFashionIQ val - ['shirt'] dataset in relative mode initialized\nFashionIQ val - ['shirt'] dataset in classic mode initialized\nFashionIQ train - ['dress', 'toptee', 'shirt'] dataset in relative mode initialized\nTraining loop started\n[0/100] train loss: 0.857 : 100%|███████████████████████████████████████████████████████████████████████████████████| 562/562 [15:33<00:00,  1.66s/it]\nextracting fashionIQ ['dress'] - val index features\n100%|█████████████████████████████████████████| 120/120 [00:24<00:00,  4.91it/s]\nCompute FashionIQ ['dress'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.74it/s]\nCompute FashionIQ ['dress'] validation metrics\nextracting fashionIQ ['toptee'] - val index features\n100%|█████████████████████████████████████████| 168/168 [00:33<00:00,  4.99it/s]\nCompute FashionIQ ['toptee'] validation predictions\n100%|███████████████████████████████████████████| 62/62 [00:04<00:00, 15.12it/s]\nCompute FashionIQ ['toptee'] validation metrics\nextracting fashionIQ ['shirt'] - val index features\n100%|█████████████████████████████████████████| 199/199 [00:39<00:00,  5.00it/s]\nCompute FashionIQ ['shirt'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.40it/s]\nCompute FashionIQ ['shirt'] validation metrics\n{\n    \"dress_recall_at10\": 31.97818398475647,\n    \"dress_recall_at50\": 57.1145236492157,\n    \"toptee_recall_at10\": 40.030595660209656,\n    \"toptee_recall_at50\": 64.50790166854858,\n    \"shirt_recall_at10\": 36.89891993999481,\n    \"shirt_recall_at50\": 58.29244256019592,\n    \"average_recall_at10\": 36.30256652832031,\n    \"average_recall_at50\": 59.97162262598673,\n    \"average_recall\": 48.13709457715352\n}\n[1/100] train loss: 0.643 : 100%|███████████████████████████████████████████████████████████████████████████████████| 562/562 [15:33<00:00,  1.66s/it]\nextracting fashionIQ ['dress'] - val index features\n100%|█████████████████████████████████████████| 120/120 [00:24<00:00,  4.97it/s]\nCompute FashionIQ ['dress'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.61it/s]\nCompute FashionIQ ['dress'] validation metrics\nextracting fashionIQ ['toptee'] - val index features\n100%|█████████████████████████████████████████| 168/168 [00:33<00:00,  4.99it/s]\nCompute FashionIQ ['toptee'] validation predictions\n100%|███████████████████████████████████████████| 62/62 [00:04<00:00, 14.96it/s]\nCompute FashionIQ ['toptee'] validation metrics\nextracting fashionIQ ['shirt'] - val index features\n100%|█████████████████████████████████████████| 199/199 [00:39<00:00,  5.00it/s]\nCompute FashionIQ ['shirt'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.45it/s]\nCompute FashionIQ ['shirt'] validation metrics\n{\n    \"dress_recall_at10\": 32.47397243976593,\n    \"dress_recall_at50\": 58.30441117286682,\n    \"toptee_recall_at10\": 42.17236042022705,\n    \"toptee_recall_at50\": 66.80265069007874,\n    \"shirt_recall_at10\": 38.61629068851471,\n    \"shirt_recall_at50\": 61.33463978767395,\n    \"average_recall_at10\": 37.75420784950256,\n    \"average_recall_at50\": 62.14723388353983,\n    \"average_recall\": 49.950720866521195\n}\n[2/100] train loss: 0.551 : 100%|███████████████████████████████████████████████████████████████████████████████████| 562/562 [15:34<00:00,  1.66s/it]\nextracting fashionIQ ['dress'] - val index features\n100%|█████████████████████████████████████████| 120/120 [00:24<00:00,  4.96it/s]\nCompute FashionIQ ['dress'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.58it/s]\nCompute FashionIQ ['dress'] validation metrics\nextracting fashionIQ ['toptee'] - val index features\n100%|█████████████████████████████████████████| 168/168 [00:33<00:00,  4.99it/s]\nCompute FashionIQ ['toptee'] validation predictions\n100%|███████████████████████████████████████████| 62/62 [00:04<00:00, 14.99it/s]\nCompute FashionIQ ['toptee'] validation metrics\nextracting fashionIQ ['shirt'] - val index features\n100%|█████████████████████████████████████████| 199/199 [00:39<00:00,  5.00it/s]\nCompute FashionIQ ['shirt'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.29it/s]\nCompute FashionIQ ['shirt'] validation metrics\n{\n    \"dress_recall_at10\": 34.209221601486206,\n    \"dress_recall_at50\": 59.692615270614624,\n    \"toptee_recall_at10\": 42.07037091255188,\n    \"toptee_recall_at50\": 67.61856079101562,\n    \"shirt_recall_at10\": 38.81256282329559,\n    \"shirt_recall_at50\": 61.33463978767395,\n    \"average_recall_at10\": 38.36405177911123,\n    \"average_recall_at50\": 62.88193861643473,\n    \"average_recall\": 50.62299519777298\n}\n[3/100] train loss: 0.486 : 100%|███████████████████████████████████████████████████████████████████████████████████| 562/562 [15:34<00:00,  1.66s/it]\nextracting fashionIQ ['dress'] - val index features\n100%|█████████████████████████████████████████| 120/120 [00:24<00:00,  4.94it/s]\nCompute FashionIQ ['dress'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.68it/s]\nCompute FashionIQ ['dress'] validation metrics\nextracting fashionIQ ['toptee'] - val index features\n100%|█████████████████████████████████████████| 168/168 [00:33<00:00,  4.99it/s]\nCompute FashionIQ ['toptee'] validation predictions\n100%|███████████████████████████████████████████| 62/62 [00:04<00:00, 15.09it/s]\nCompute FashionIQ ['toptee'] validation metrics\nextracting fashionIQ ['shirt'] - val index features\n100%|█████████████████████████████████████████| 199/199 [00:39<00:00,  4.98it/s]\nCompute FashionIQ ['shirt'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.41it/s]\nCompute FashionIQ ['shirt'] validation metrics\n{\n    \"dress_recall_at10\": 34.65542793273926,\n    \"dress_recall_at50\": 60.73376536369324,\n    \"toptee_recall_at10\": 42.17236042022705,\n    \"toptee_recall_at50\": 67.36359000205994,\n    \"shirt_recall_at10\": 39.352306723594666,\n    \"shirt_recall_at50\": 61.48184537887573,\n    \"average_recall_at10\": 38.72669835885366,\n    \"average_recall_at50\": 63.193066914876304,\n    \"average_recall\": 50.95988263686498\n}\n[4/100] train loss: 0.431 : 100%|███████████████████████████████████████████████████████████████████████████████████| 562/562 [15:34<00:00,  1.66s/it]\nextracting fashionIQ ['dress'] - val index features\n100%|█████████████████████████████████████████| 120/120 [00:24<00:00,  4.97it/s]\nCompute FashionIQ ['dress'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.70it/s]\nCompute FashionIQ ['dress'] validation metrics\nextracting fashionIQ ['toptee'] - val index features\n100%|█████████████████████████████████████████| 168/168 [00:33<00:00,  4.99it/s]\nCompute FashionIQ ['toptee'] validation predictions\n100%|███████████████████████████████████████████| 62/62 [00:04<00:00, 14.97it/s]\nCompute FashionIQ ['toptee'] validation metrics\nextracting fashionIQ ['shirt'] - val index features\n100%|█████████████████████████████████████████| 199/199 [00:39<00:00,  5.00it/s]\nCompute FashionIQ ['shirt'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.48it/s]\nCompute FashionIQ ['shirt'] validation metrics\n{\n    \"dress_recall_at10\": 34.85374450683594,\n    \"dress_recall_at50\": 60.53544878959656,\n    \"toptee_recall_at10\": 42.42733418941498,\n    \"toptee_recall_at50\": 66.70066118240356,\n    \"shirt_recall_at10\": 40.33366143703461,\n    \"shirt_recall_at50\": 61.629050970077515,\n    \"average_recall_at10\": 39.20491337776184,\n    \"average_recall_at50\": 62.955053647359215,\n    \"average_recall\": 51.07998351256053\n}\n[5/100] train loss: 0.373 : 100%|███████████████████████████████████████████████████████████████████████████████████| 562/562 [15:33<00:00,  1.66s/it]\nextracting fashionIQ ['dress'] - val index features\n100%|█████████████████████████████████████████| 120/120 [00:24<00:00,  4.97it/s]\nCompute FashionIQ ['dress'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.53it/s]\nCompute FashionIQ ['dress'] validation metrics\nextracting fashionIQ ['toptee'] - val index features\n100%|█████████████████████████████████████████| 168/168 [00:33<00:00,  4.98it/s]\nCompute FashionIQ ['toptee'] validation predictions\n100%|███████████████████████████████████████████| 62/62 [00:04<00:00, 15.13it/s]\nCompute FashionIQ ['toptee'] validation metrics\nextracting fashionIQ ['shirt'] - val index features\n100%|█████████████████████████████████████████| 199/199 [00:39<00:00,  4.99it/s]\nCompute FashionIQ ['shirt'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.48it/s]\nCompute FashionIQ ['shirt'] validation metrics\n{\n    \"dress_recall_at10\": 34.60584878921509,\n    \"dress_recall_at50\": 60.38671135902405,\n    \"toptee_recall_at10\": 42.580315470695496,\n    \"toptee_recall_at50\": 66.9046401977539,\n    \"shirt_recall_at10\": 39.303237199783325,\n    \"shirt_recall_at50\": 61.43277883529663,\n    \"average_recall_at10\": 38.829800486564636,\n    \"average_recall_at50\": 62.908043464024864,\n    \"average_recall\": 50.868921975294754\n}\n[6/100] train loss: 0.348 : 100%|███████████████████████████████████████████████████████████████████████████████████| 562/562 [15:33<00:00,  1.66s/it]\nextracting fashionIQ ['dress'] - val index features\n100%|█████████████████████████████████████████| 120/120 [00:24<00:00,  4.96it/s]\nCompute FashionIQ ['dress'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.69it/s]\nCompute FashionIQ ['dress'] validation metrics\nextracting fashionIQ ['toptee'] - val index features\n100%|█████████████████████████████████████████| 168/168 [00:33<00:00,  4.99it/s]\nCompute FashionIQ ['toptee'] validation predictions\n100%|███████████████████████████████████████████| 62/62 [00:04<00:00, 14.91it/s]\nCompute FashionIQ ['toptee'] validation metrics\nextracting fashionIQ ['shirt'] - val index features\n100%|█████████████████████████████████████████| 199/199 [00:39<00:00,  5.00it/s]\nCompute FashionIQ ['shirt'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.54it/s]\nCompute FashionIQ ['shirt'] validation metrics\n{\n    \"dress_recall_at10\": 35.44868528842926,\n    \"dress_recall_at50\": 61.47744059562683,\n    \"toptee_recall_at10\": 42.580315470695496,\n    \"toptee_recall_at50\": 67.87353157997131,\n    \"shirt_recall_at10\": 41.06967747211456,\n    \"shirt_recall_at50\": 63.395488262176514,\n    \"average_recall_at10\": 39.69955941041311,\n    \"average_recall_at50\": 64.24882014592488,\n    \"average_recall\": 51.97418977816899\n}\n[7/100] train loss: 0.318 : 100%|███████████████████████████████████████████████████████████████████████████████████| 562/562 [15:33<00:00,  1.66s/it]\nextracting fashionIQ ['dress'] - val index features\n100%|█████████████████████████████████████████| 120/120 [00:24<00:00,  4.96it/s]\nCompute FashionIQ ['dress'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.55it/s]\nCompute FashionIQ ['dress'] validation metrics\nextracting fashionIQ ['toptee'] - val index features\n100%|█████████████████████████████████████████| 168/168 [00:33<00:00,  4.99it/s]\nCompute FashionIQ ['toptee'] validation predictions\n100%|███████████████████████████████████████████| 62/62 [00:04<00:00, 15.05it/s]\nCompute FashionIQ ['toptee'] validation metrics\nextracting fashionIQ ['shirt'] - val index features\n100%|█████████████████████████████████████████| 199/199 [00:39<00:00,  4.98it/s]\nCompute FashionIQ ['shirt'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.52it/s]\nCompute FashionIQ ['shirt'] validation metrics\n{\n    \"dress_recall_at10\": 34.308379888534546,\n    \"dress_recall_at50\": 59.791767597198486,\n    \"toptee_recall_at10\": 41.50943458080292,\n    \"toptee_recall_at50\": 66.29270911216736,\n    \"shirt_recall_at10\": 39.10696804523468,\n    \"shirt_recall_at50\": 61.23650670051575,\n    \"average_recall_at10\": 38.30826083819071,\n    \"average_recall_at50\": 62.44032780329386,\n    \"average_recall\": 50.37429432074229\n}\n[8/100] train loss: 0.295 : 100%|███████████████████████████████████████████████████████████████████████████████████| 562/562 [15:33<00:00,  1.66s/it]\nextracting fashionIQ ['dress'] - val index features\n100%|█████████████████████████████████████████| 120/120 [00:24<00:00,  4.98it/s]\nCompute FashionIQ ['dress'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.61it/s]\nCompute FashionIQ ['dress'] validation metrics\nextracting fashionIQ ['toptee'] - val index features\n100%|█████████████████████████████████████████| 168/168 [00:33<00:00,  4.99it/s]\nCompute FashionIQ ['toptee'] validation predictions\n100%|███████████████████████████████████████████| 62/62 [00:04<00:00, 15.08it/s]\nCompute FashionIQ ['toptee'] validation metrics\nextracting fashionIQ ['shirt'] - val index features\n100%|█████████████████████████████████████████| 199/199 [00:39<00:00,  5.00it/s]\nCompute FashionIQ ['shirt'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.45it/s]\nCompute FashionIQ ['shirt'] validation metrics\n{\n    \"dress_recall_at10\": 35.29995083808899,\n    \"dress_recall_at50\": 60.73376536369324,\n    \"toptee_recall_at10\": 43.54920983314514,\n    \"toptee_recall_at50\": 66.70066118240356,\n    \"shirt_recall_at10\": 38.861629366874695,\n    \"shirt_recall_at50\": 61.9725227355957,\n    \"average_recall_at10\": 39.23693001270294,\n    \"average_recall_at50\": 63.13564976056417,\n    \"average_recall\": 51.18628988663356\n}\n[9/100] train loss: 0.260 : 100%|███████████████████████████████████████████████████████████████████████████████████| 562/562 [15:33<00:00,  1.66s/it]\nextracting fashionIQ ['dress'] - val index features\n100%|█████████████████████████████████████████| 120/120 [00:24<00:00,  4.97it/s]\nCompute FashionIQ ['dress'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.51it/s]\nCompute FashionIQ ['dress'] validation metrics\nextracting fashionIQ ['toptee'] - val index features\n100%|█████████████████████████████████████████| 168/168 [00:33<00:00,  4.97it/s]\nCompute FashionIQ ['toptee'] validation predictions\n100%|███████████████████████████████████████████| 62/62 [00:03<00:00, 15.54it/s]\nCompute FashionIQ ['toptee'] validation metrics\nextracting fashionIQ ['shirt'] - val index features\n100%|█████████████████████████████████████████| 199/199 [00:39<00:00,  4.99it/s]\nCompute FashionIQ ['shirt'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.51it/s]\nCompute FashionIQ ['shirt'] validation metrics\n{\n    \"dress_recall_at10\": 34.70500707626343,\n    \"dress_recall_at50\": 61.17997169494629,\n    \"toptee_recall_at10\": 42.223355174064636,\n    \"toptee_recall_at50\": 65.83375930786133,\n    \"shirt_recall_at10\": 40.43179452419281,\n    \"shirt_recall_at50\": 62.65947222709656,\n    \"average_recall_at10\": 39.12005225817362,\n    \"average_recall_at50\": 63.22440107663473,\n    \"average_recall\": 51.172226667404175\n}\n[10/100] train loss: 0.244 : 100%|██████████████████████████████████████████████████████████████████████████████████| 562/562 [15:33<00:00,  1.66s/it]\nextracting fashionIQ ['dress'] - val index features\n100%|█████████████████████████████████████████| 120/120 [00:24<00:00,  4.97it/s]\nCompute FashionIQ ['dress'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.67it/s]\nCompute FashionIQ ['dress'] validation metrics\nextracting fashionIQ ['toptee'] - val index features\n100%|█████████████████████████████████████████| 168/168 [00:33<00:00,  4.98it/s]\nCompute FashionIQ ['toptee'] validation predictions\n100%|███████████████████████████████████████████| 62/62 [00:04<00:00, 15.07it/s]\nCompute FashionIQ ['toptee'] validation metrics\nextracting fashionIQ ['shirt'] - val index features\n100%|█████████████████████████████████████████| 199/199 [00:39<00:00,  4.98it/s]\nCompute FashionIQ ['shirt'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.51it/s]\nCompute FashionIQ ['shirt'] validation metrics\n{\n    \"dress_recall_at10\": 35.94447076320648,\n    \"dress_recall_at50\": 61.527019739151,\n    \"toptee_recall_at10\": 43.1412547826767,\n    \"toptee_recall_at50\": 67.56756901741028,\n    \"shirt_recall_at10\": 41.02060794830322,\n    \"shirt_recall_at50\": 62.512266635894775,\n    \"average_recall_at10\": 40.035444498062134,\n    \"average_recall_at50\": 63.86895179748535,\n    \"average_recall\": 51.95219814777374\n}\n[11/100] train loss: 0.227 : 100%|██████████████████████████████████████████████████████████████████████████████████| 562/562 [15:33<00:00,  1.66s/it]\nextracting fashionIQ ['dress'] - val index features\n100%|█████████████████████████████████████████| 120/120 [00:24<00:00,  4.97it/s]\nCompute FashionIQ ['dress'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.76it/s]\nCompute FashionIQ ['dress'] validation metrics\nextracting fashionIQ ['toptee'] - val index features\n100%|█████████████████████████████████████████| 168/168 [00:33<00:00,  4.99it/s]\nCompute FashionIQ ['toptee'] validation predictions\n100%|███████████████████████████████████████████| 62/62 [00:04<00:00, 15.08it/s]\nCompute FashionIQ ['toptee'] validation metrics\nextracting fashionIQ ['shirt'] - val index features\n100%|█████████████████████████████████████████| 199/199 [00:39<00:00,  5.00it/s]\nCompute FashionIQ ['shirt'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.53it/s]\nCompute FashionIQ ['shirt'] validation metrics\n{\n    \"dress_recall_at10\": 34.70500707626343,\n    \"dress_recall_at50\": 59.841346740722656,\n    \"toptee_recall_at10\": 43.65119934082031,\n    \"toptee_recall_at50\": 66.80265069007874,\n    \"shirt_recall_at10\": 39.842984080314636,\n    \"shirt_recall_at50\": 63.444554805755615,\n    \"average_recall_at10\": 39.39973016579946,\n    \"average_recall_at50\": 63.362850745519005,\n    \"average_recall\": 51.38129045565923\n}\n[12/100] train loss: 0.206 : 100%|██████████████████████████████████████████████████████████████████████████████████| 562/562 [15:34<00:00,  1.66s/it]\nextracting fashionIQ ['dress'] - val index features\n100%|█████████████████████████████████████████| 120/120 [00:24<00:00,  4.97it/s]\nCompute FashionIQ ['dress'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.64it/s]\nCompute FashionIQ ['dress'] validation metrics\nextracting fashionIQ ['toptee'] - val index features\n100%|█████████████████████████████████████████| 168/168 [00:33<00:00,  4.99it/s]\nCompute FashionIQ ['toptee'] validation predictions\n100%|███████████████████████████████████████████| 62/62 [00:04<00:00, 15.10it/s]\nCompute FashionIQ ['toptee'] validation metrics\nextracting fashionIQ ['shirt'] - val index features\n100%|█████████████████████████████████████████| 199/199 [00:39<00:00,  5.00it/s]\nCompute FashionIQ ['shirt'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.53it/s]\nCompute FashionIQ ['shirt'] validation metrics\n{\n    \"dress_recall_at10\": 33.316805958747864,\n    \"dress_recall_at50\": 58.84977579116821,\n    \"toptee_recall_at10\": 43.24324429035187,\n    \"toptee_recall_at50\": 67.1596109867096,\n    \"shirt_recall_at10\": 39.352306723594666,\n    \"shirt_recall_at50\": 61.530911922454834,\n    \"average_recall_at10\": 38.63745232423147,\n    \"average_recall_at50\": 62.51343290011088,\n    \"average_recall\": 50.57544261217117\n}\n[13/100] train loss: 0.196 : 100%|██████████████████████████████████████████████████████████████████████████████████| 562/562 [15:34<00:00,  1.66s/it]\nextracting fashionIQ ['dress'] - val index features\n100%|█████████████████████████████████████████| 120/120 [00:24<00:00,  4.97it/s]\nCompute FashionIQ ['dress'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.65it/s]\nCompute FashionIQ ['dress'] validation metrics\nextracting fashionIQ ['toptee'] - val index features\n100%|█████████████████████████████████████████| 168/168 [00:33<00:00,  4.99it/s]\nCompute FashionIQ ['toptee'] validation predictions\n100%|███████████████████████████████████████████| 62/62 [00:04<00:00, 14.99it/s]\nCompute FashionIQ ['toptee'] validation metrics\nextracting fashionIQ ['shirt'] - val index features\n100%|█████████████████████████████████████████| 199/199 [00:39<00:00,  5.00it/s]\nCompute FashionIQ ['shirt'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.52it/s]\nCompute FashionIQ ['shirt'] validation metrics\n{\n    \"dress_recall_at10\": 33.614277839660645,\n    \"dress_recall_at50\": 59.940505027770996,\n    \"toptee_recall_at10\": 42.121365666389465,\n    \"toptee_recall_at50\": 66.70066118240356,\n    \"shirt_recall_at10\": 39.352306723594666,\n    \"shirt_recall_at50\": 61.87438368797302,\n    \"average_recall_at10\": 38.362650076548256,\n    \"average_recall_at50\": 62.83851663271586,\n    \"average_recall\": 50.60058335463206\n}\n[14/100] train loss: 0.184 : 100%|██████████████████████████████████████████████████████████████████████████████████| 562/562 [15:33<00:00,  1.66s/it]\nextracting fashionIQ ['dress'] - val index features\n100%|█████████████████████████████████████████| 120/120 [00:24<00:00,  4.96it/s]\nCompute FashionIQ ['dress'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.64it/s]\nCompute FashionIQ ['dress'] validation metrics\nextracting fashionIQ ['toptee'] - val index features\n100%|█████████████████████████████████████████| 168/168 [00:33<00:00,  4.98it/s]\nCompute FashionIQ ['toptee'] validation predictions\n100%|███████████████████████████████████████████| 62/62 [00:04<00:00, 15.06it/s]\nCompute FashionIQ ['toptee'] validation metrics\nextracting fashionIQ ['shirt'] - val index features\n100%|█████████████████████████████████████████| 199/199 [00:39<00:00,  5.00it/s]\nCompute FashionIQ ['shirt'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.33it/s]\nCompute FashionIQ ['shirt'] validation metrics\n{\n    \"dress_recall_at10\": 33.46554338932037,\n    \"dress_recall_at50\": 59.643036127090454,\n    \"toptee_recall_at10\": 42.37633943557739,\n    \"toptee_recall_at50\": 66.4966881275177,\n    \"shirt_recall_at10\": 39.45044279098511,\n    \"shirt_recall_at50\": 61.77625060081482,\n    \"average_recall_at10\": 38.43077520529429,\n    \"average_recall_at50\": 62.63865828514099,\n    \"average_recall\": 50.53471674521764\n}\n[15/100] train loss: 0.178 : 100%|██████████████████████████████████████████████████████████████████████████████████| 562/562 [15:34<00:00,  1.66s/it]\nextracting fashionIQ ['dress'] - val index features\n100%|█████████████████████████████████████████| 120/120 [00:24<00:00,  4.96it/s]\nCompute FashionIQ ['dress'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.64it/s]\nCompute FashionIQ ['dress'] validation metrics\nextracting fashionIQ ['toptee'] - val index features\n100%|█████████████████████████████████████████| 168/168 [00:33<00:00,  4.98it/s]\nCompute FashionIQ ['toptee'] validation predictions\n100%|███████████████████████████████████████████| 62/62 [00:04<00:00, 14.94it/s]\nCompute FashionIQ ['toptee'] validation metrics\nextracting fashionIQ ['shirt'] - val index features\n100%|█████████████████████████████████████████| 199/199 [00:39<00:00,  5.00it/s]\nCompute FashionIQ ['shirt'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.47it/s]\nCompute FashionIQ ['shirt'] validation metrics\n{\n    \"dress_recall_at10\": 33.51512253284454,\n    \"dress_recall_at50\": 60.039663314819336,\n    \"toptee_recall_at10\": 41.40744507312775,\n    \"toptee_recall_at50\": 65.68077802658081,\n    \"shirt_recall_at10\": 39.69578146934509,\n    \"shirt_recall_at50\": 61.138373613357544,\n    \"average_recall_at10\": 38.206116358439125,\n    \"average_recall_at50\": 62.2862716515859,\n    \"average_recall\": 50.24619400501251\n}\n[16/100] train loss: 0.170 : 100%|██████████████████████████████████████████████████████████████████████████████████| 562/562 [15:34<00:00,  1.66s/it]\nextracting fashionIQ ['dress'] - val index features\n100%|█████████████████████████████████████████| 120/120 [00:24<00:00,  4.96it/s]\nCompute FashionIQ ['dress'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.59it/s]\nCompute FashionIQ ['dress'] validation metrics\nextracting fashionIQ ['toptee'] - val index features\n100%|█████████████████████████████████████████| 168/168 [00:33<00:00,  4.98it/s]\nCompute FashionIQ ['toptee'] validation predictions\n100%|███████████████████████████████████████████| 62/62 [00:04<00:00, 15.00it/s]\nCompute FashionIQ ['toptee'] validation metrics\nextracting fashionIQ ['shirt'] - val index features\n100%|█████████████████████████████████████████| 199/199 [00:39<00:00,  5.00it/s]\nCompute FashionIQ ['shirt'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.36it/s]\nCompute FashionIQ ['shirt'] validation metrics\n{\n    \"dress_recall_at10\": 33.564698696136475,\n    \"dress_recall_at50\": 58.60188603401184,\n    \"toptee_recall_at10\": 41.91738963127136,\n    \"toptee_recall_at50\": 66.3437008857727,\n    \"shirt_recall_at10\": 39.793914556503296,\n    \"shirt_recall_at50\": 62.16879487037659,\n    \"average_recall_at10\": 38.42533429463705,\n    \"average_recall_at50\": 62.371460596720375,\n    \"average_recall\": 50.39839744567871\n}\n[17/100] train loss: 0.156 : 100%|██████████████████████████████████████████████████████████████████████████████████| 562/562 [15:34<00:00,  1.66s/it]\nextracting fashionIQ ['dress'] - val index features\n100%|█████████████████████████████████████████| 120/120 [00:24<00:00,  4.96it/s]\nCompute FashionIQ ['dress'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.65it/s]\nCompute FashionIQ ['dress'] validation metrics\nextracting fashionIQ ['toptee'] - val index features\n100%|█████████████████████████████████████████| 168/168 [00:33<00:00,  4.99it/s]\nCompute FashionIQ ['toptee'] validation predictions\n100%|███████████████████████████████████████████| 62/62 [00:04<00:00, 14.98it/s]\nCompute FashionIQ ['toptee'] validation metrics\nextracting fashionIQ ['shirt'] - val index features\n100%|█████████████████████████████████████████| 199/199 [00:39<00:00,  5.00it/s]\nCompute FashionIQ ['shirt'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.46it/s]\nCompute FashionIQ ['shirt'] validation metrics\n{\n    \"dress_recall_at10\": 34.110063314437866,\n    \"dress_recall_at50\": 58.94893407821655,\n    \"toptee_recall_at10\": 42.37633943557739,\n    \"toptee_recall_at50\": 66.08873009681702,\n    \"shirt_recall_at10\": 38.22374939918518,\n    \"shirt_recall_at50\": 61.9234561920166,\n    \"average_recall_at10\": 38.23671738306681,\n    \"average_recall_at50\": 62.32037345568339,\n    \"average_recall\": 50.2785454193751\n}\n[18/100] train loss: 0.156 : 100%|██████████████████████████████████████████████████████████████████████████████████| 562/562 [15:34<00:00,  1.66s/it]\nextracting fashionIQ ['dress'] - val index features\n100%|█████████████████████████████████████████| 120/120 [00:24<00:00,  4.96it/s]\nCompute FashionIQ ['dress'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.57it/s]\nCompute FashionIQ ['dress'] validation metrics\nextracting fashionIQ ['toptee'] - val index features\n100%|█████████████████████████████████████████| 168/168 [00:33<00:00,  4.98it/s]\nCompute FashionIQ ['toptee'] validation predictions\n100%|███████████████████████████████████████████| 62/62 [00:04<00:00, 14.88it/s]\nCompute FashionIQ ['toptee'] validation metrics\nextracting fashionIQ ['shirt'] - val index features\n100%|█████████████████████████████████████████| 199/199 [00:39<00:00,  5.00it/s]\nCompute FashionIQ ['shirt'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.35it/s]\nCompute FashionIQ ['shirt'] validation metrics\n{\n    \"dress_recall_at10\": 33.16807150840759,\n    \"dress_recall_at50\": 58.35399031639099,\n    \"toptee_recall_at10\": 41.40744507312775,\n    \"toptee_recall_at50\": 64.86486196517944,\n    \"shirt_recall_at10\": 38.66535723209381,\n    \"shirt_recall_at50\": 60.05887985229492,\n    \"average_recall_at10\": 37.74695793787638,\n    \"average_recall_at50\": 61.092577377955116,\n    \"average_recall\": 49.41976765791575\n}\n[19/100] train loss: 0.137 : 100%|██████████████████████████████████████████████████████████████████████████████████| 562/562 [15:34<00:00,  1.66s/it]\nextracting fashionIQ ['dress'] - val index features\n100%|█████████████████████████████████████████| 120/120 [00:24<00:00,  4.96it/s]\nCompute FashionIQ ['dress'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.54it/s]\nCompute FashionIQ ['dress'] validation metrics\nextracting fashionIQ ['toptee'] - val index features\n100%|█████████████████████████████████████████| 168/168 [00:33<00:00,  4.97it/s]\nCompute FashionIQ ['toptee'] validation predictions\n100%|███████████████████████████████████████████| 62/62 [00:04<00:00, 14.92it/s]\nCompute FashionIQ ['toptee'] validation metrics\nextracting fashionIQ ['shirt'] - val index features\n100%|█████████████████████████████████████████| 199/199 [00:39<00:00,  4.99it/s]\nCompute FashionIQ ['shirt'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.62it/s]\nCompute FashionIQ ['shirt'] validation metrics\n{\n    \"dress_recall_at10\": 32.92017877101898,\n    \"dress_recall_at50\": 58.40356945991516,\n    \"toptee_recall_at10\": 40.59153497219086,\n    \"toptee_recall_at50\": 64.20193910598755,\n    \"shirt_recall_at10\": 39.00883197784424,\n    \"shirt_recall_at50\": 61.48184537887573,\n    \"average_recall_at10\": 37.50684857368469,\n    \"average_recall_at50\": 61.36245131492615,\n    \"average_recall\": 49.43464994430542\n}\n[20/100] train loss: 0.136 : 100%|██████████████████████████████████████████████████████████████████████████████████| 562/562 [15:34<00:00,  1.66s/it]\nextracting fashionIQ ['dress'] - val index features\n100%|█████████████████████████████████████████| 120/120 [00:24<00:00,  4.97it/s]\nCompute FashionIQ ['dress'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.60it/s]\nCompute FashionIQ ['dress'] validation metrics\nextracting fashionIQ ['toptee'] - val index features\n100%|█████████████████████████████████████████| 168/168 [00:33<00:00,  4.98it/s]\nCompute FashionIQ ['toptee'] validation predictions\n100%|███████████████████████████████████████████| 62/62 [00:04<00:00, 14.86it/s]\nCompute FashionIQ ['toptee'] validation metrics\nextracting fashionIQ ['shirt'] - val index features\n100%|█████████████████████████████████████████| 199/199 [00:39<00:00,  5.00it/s]\nCompute FashionIQ ['shirt'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.45it/s]\nCompute FashionIQ ['shirt'] validation metrics\n{\n    \"dress_recall_at10\": 33.366385102272034,\n    \"dress_recall_at50\": 58.80019664764404,\n    \"toptee_recall_at10\": 41.764405369758606,\n    \"toptee_recall_at50\": 65.62978029251099,\n    \"shirt_recall_at10\": 39.59764540195465,\n    \"shirt_recall_at50\": 61.04023456573486,\n    \"average_recall_at10\": 38.242811957995094,\n    \"average_recall_at50\": 61.82340383529663,\n    \"average_recall\": 50.03310789664586\n}\n[21/100] train loss: 0.125 : 100%|██████████████████████████████████████████████████████████████████████████████████| 562/562 [15:34<00:00,  1.66s/it]\nextracting fashionIQ ['dress'] - val index features\n100%|█████████████████████████████████████████| 120/120 [00:24<00:00,  4.94it/s]\nCompute FashionIQ ['dress'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.56it/s]\nCompute FashionIQ ['dress'] validation metrics\nextracting fashionIQ ['toptee'] - val index features\n100%|█████████████████████████████████████████| 168/168 [00:33<00:00,  4.99it/s]\nCompute FashionIQ ['toptee'] validation predictions\n100%|███████████████████████████████████████████| 62/62 [00:04<00:00, 15.06it/s]\nCompute FashionIQ ['toptee'] validation metrics\nextracting fashionIQ ['shirt'] - val index features\n100%|█████████████████████████████████████████| 199/199 [00:39<00:00,  4.99it/s]\nCompute FashionIQ ['shirt'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.45it/s]\nCompute FashionIQ ['shirt'] validation metrics\n{\n    \"dress_recall_at10\": 32.77144134044647,\n    \"dress_recall_at50\": 58.15567970275879,\n    \"toptee_recall_at10\": 41.81540012359619,\n    \"toptee_recall_at50\": 66.29270911216736,\n    \"shirt_recall_at10\": 39.00883197784424,\n    \"shirt_recall_at50\": 60.745829343795776,\n    \"average_recall_at10\": 37.86522448062897,\n    \"average_recall_at50\": 61.73140605290731,\n    \"average_recall\": 49.79831526676814\n}\n[22/100] train loss: 0.124 : 100%|██████████████████████████████████████████████████████████████████████████████████| 562/562 [15:34<00:00,  1.66s/it]\nextracting fashionIQ ['dress'] - val index features\n100%|█████████████████████████████████████████| 120/120 [00:24<00:00,  4.97it/s]\nCompute FashionIQ ['dress'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.65it/s]\nCompute FashionIQ ['dress'] validation metrics\nextracting fashionIQ ['toptee'] - val index features\n100%|█████████████████████████████████████████| 168/168 [00:33<00:00,  4.99it/s]\nCompute FashionIQ ['toptee'] validation predictions\n100%|███████████████████████████████████████████| 62/62 [00:04<00:00, 14.93it/s]\nCompute FashionIQ ['toptee'] validation metrics\nextracting fashionIQ ['shirt'] - val index features\n100%|█████████████████████████████████████████| 199/199 [00:39<00:00,  5.00it/s]\nCompute FashionIQ ['shirt'] validation predictions\n100%|███████████████████████████████████████████| 64/64 [00:04<00:00, 15.34it/s]\nCompute FashionIQ ['shirt'] validation metrics\n{\n    \"dress_recall_at10\": 32.87059962749481,\n    \"dress_recall_at50\": 58.45314860343933,\n    \"toptee_recall_at10\": 41.50943458080292,\n    \"toptee_recall_at50\": 65.3748095035553,\n    \"shirt_recall_at10\": 38.910695910453796,\n    \"shirt_recall_at50\": 60.745829343795776,\n    \"average_recall_at10\": 37.76357670625051,\n    \"average_recall_at50\": 61.52459581693014,\n    \"average_recall\": 49.644086261590324\n}\n[23/100] train loss: 0.122 :  61%|█████████████████████████████████████████████████▉                                | 342/562 [09:29<06:05,  1.66s/it]","output_type":"stream"}],"execution_count":null}]}